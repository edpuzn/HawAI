# HawAI Monorepo

HawAI, SDG-3 (SaÄŸlÄ±k ve Kaliteli YaÅŸam) odaklÄ± bir yapay zekÃ¢ saÄŸlÄ±k yardÄ±mcÄ±sÄ±dÄ±r. Bu depo; FastAPI backend, Vue 3 + Vite frontend ve (opsiyonel) Dify entegrasyonunu iÃ§erir.

## ðŸ† BaÅŸarÄ±lar

- **Huawei Kodlama Maratonu 2024 - 3. LÃ¼k** ðŸ¥‰
  - Bu proje Huawei Cloud teknolojileri kullanÄ±larak geliÅŸtirilmiÅŸ ve Huawei Kodlama Maratonu'nda 3. lÃ¼k Ã¶dÃ¼lÃ¼ kazanmÄ±ÅŸtÄ±r.
  - Huawei Cloud SWR (Software Repository for Container) ve CCE (Cloud Container Engine) ile deploy edilmiÅŸtir.

## Dizin YapÄ±sÄ±
- `HawAI-backend/` â€” FastAPI tabanlÄ± API, model seed scriptleri ve Makefile hedefi
- `HawAI-frontend/` â€” Vue 3 + Vite + TypeScript arayÃ¼z
- `dify/` â€” Dify entegrasyonlarÄ± ve Ã¶rnekler (opsiyonel)

---

## Gereksinimler
- Python 3.11+
- Node.js 18+ (pnpm/yarn/npm)
- Docker (Ollama konteyneri iÃ§in)
- curl, jq (kolay test iÃ§in)

Ollama varsayÄ±lan eriÅŸim: `http://localhost:11434`

> Not: Ollama konteyner adÄ± scriptte `hawai-ollama` olarak varsayÄ±lmÄ±ÅŸtÄ±r. FarklÄ±ysa `HawAI-backend/scripts/seed_ollama.sh` iÃ§indeki adÄ± gÃ¼ncelleyin.

---

## Backend (FastAPI)

### 1) Kurulum
```bash
cd HawAI-backend
python3.11 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
cp .env.example .env
```

`.env` Ã¶rneÄŸi:
```
OLLAMA_HOST=http://localhost:11434
MODEL_NAME=hawai-sdg3
ALLOWED_ORIGINS=http://localhost:5173
RATE_LIMIT_PER_MINUTE=60
RATE_LIMIT_KEY_MODE=api_key_or_ip
LOG_LEVEL=INFO
WORKERS=1
```

### 2) Model Seed (Ollama)
```bash
# Tagâ€™leri gÃ¶r
curl -s http://localhost:11434/api/tags | jq .

# Modeli oluÅŸtur/seed et (8B, gerekirse 3B fallback)
bash scripts/seed_ollama.sh
# veya
make hawai-model
```
Beklenen model adÄ±: `hawai-sdg3`.

HÄ±zlÄ± Ã¼retim testi:
```bash
curl -s http://localhost:11434/api/generate -d '{
  "model": "hawai-sdg3",
  "prompt": "Tip 2 diyabette beslenme iÃ§in pratik Ã¶neriler verir misin?"
}' | jq -r '.response'
```

### 3) Ã‡alÄ±ÅŸtÄ±rma
GeliÅŸtirme modu:
```bash
source .venv/bin/activate
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

Ãœretim benzeri (opsiyonel):
```bash
# WORKERS ve LOG_LEVEL .envâ€™den okunur
gunicorn -k uvicorn.workers.UvicornWorker -w ${WORKERS:-2} -b 0.0.0.0:8000 app.main:app
```

### 4) SaÄŸlÄ±k ve API Testleri
```bash
# Health
curl -s http://localhost:8000/healthz | jq .

# Basit chat testi
curl -s -X POST http://localhost:8000/chat \
  -H 'Content-Type: application/json' \
  -H 'X-API-Key: demo-key' \
  -d '{"message":"Tip 2 diyabette beslenme iÃ§in pratik Ã¶neriler?"}' | jq .
```

---

## Frontend (Vue 3 + Vite)
```bash
cd HawAI-frontend/frontend
# Paket yÃ¶neticinizi seÃ§in (pnpm/yarn/npm)
pnpm i  # veya yarn / npm i

# .env
cat > .env <<EOT
VITE_API_URL=http://localhost:8000
VITE_API_KEY=demo-key
EOT

# GeliÅŸtirme sunucusu
pnpm run dev -- --host --port 5173  # veya eÅŸdeÄŸeri
```

VarsayÄ±lan adres: `http://localhost:5173`

---

## Makefile (Backend)
`HawAI-backend/Makefile` iÃ§inde model seed hedefi vardÄ±r:
```
.PHONY: hawai-model
hawai-model:
	@echo "[make] HawAI modeli Ollamaâ€™ya ekleniyor..."
	@bash scripts/seed_ollama.sh
	@echo "[make] TamamlandÄ±."
```

KullanÄ±m:
```bash
cd HawAI-backend
make hawai-model
```

---

## Sorun Giderme
- Model bulunamadÄ±: `MODEL_NAME=hawai-sdg3` ve `curl /api/tags` ile doÄŸrulayÄ±n, `scripts/seed_ollama.sh` Ã§alÄ±ÅŸtÄ±rÄ±n.
- OLLAMA_HOST ulaÅŸÄ±lamÄ±yor: Docker konteyner ve port mappingâ€™i kontrol edin.
- CORS hatasÄ±: Backend `.env` iÃ§indeki `ALLOWED_ORIGINS`â€™i gÃ¼ncelleyin ve yeniden baÅŸlatÄ±n.
- 429 rate limit: `RATE_LIMIT_PER_MINUTE` deÄŸerini artÄ±rÄ±n veya bekleyip tekrar deneyin.
- API key: Ä°stekte `X-API-Key` baÅŸlÄ±ÄŸÄ±nÄ± gÃ¶nderin (Ã¶rn. `demo-key`).

---

## Lisans
Bu depo iÃ§indeki her alt proje kendi lisans ve READMEâ€™sine referans verebilir. AyrÄ±ntÄ±lar iÃ§in ilgili klasÃ¶rleri inceleyin.
